{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling tensors with PyTorch\n",
    "At its core, PyTorch is a library that provides multidimensional arrays, called tensors in\n",
    "PyTorch parlance, and an extensive library of operations on them is provided by the torch module. Both tensors and related operations can run on the CPU or GPU. The second core thing that PyTorch allows tensors to keep track of the operations performed on them and to compute derivatives of an output with respect to any of its inputs analytically via backpropagation.\n",
    "\n",
    "**Key points**\n",
    "\n",
    "- Numbers in Python are full-fledged objects.\n",
    "- Lists in Python are meant for sequential collections of objects.\n",
    "- The Python interpreter is slow compared with optimized, compiled code\n",
    "\n",
    "[picture]\n",
    "\n",
    "PyTorch tensors or NumPy arrays, on the other hand, are views over (typically) contiguous memory blocks containing unboxed C numeric types, not Python objects. So a 1D tensor of 1 million float numbers requires 4 million contiguous bytes to be stored, plus a small overhead for the metadata (dimensions, numeric type, and so on).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "https://openreview.net/pdf?id=BJJsrmfCZ\n",
    "\n",
    "https://pytorch.org/docs/stable/index.html\n",
    "\n",
    "https://pytorch.org/tutorials/\n",
    "\n",
    "https://www.youtube.com/watch?v=f5liqUk0ZTw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Tensors](https://pytorch.org/docs/stable/tensors.html?highlight=tensor#torch.Tensor)\n",
    "\n",
    "https://www.youtube.com/watch?v=f5liqUk0ZTw\n",
    "\n",
    "https://pytorch.org/docs/stable/torch.html#torch.tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch-Numpy interoperability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.17767131  0.79011993  1.0483228 ]\n",
      " [ 1.13219891 -3.00794146  1.57530639]]\n",
      "\n",
      "tensor([[ 1.1777,  0.7901,  1.0483],\n",
      "        [ 1.1322, -3.0079,  1.5753]], dtype=torch.float64)\n",
      "\n",
      "[[ 1.17767131  0.79011993  1.0483228 ]\n",
      " [ 1.13219891 -3.00794146  1.57530639]]\n"
     ]
    }
   ],
   "source": [
    "a_np = np.random.randn(2, 3)\n",
    "print(a_np)\n",
    "print() \n",
    "\n",
    "a = torch.tensor(a_np) # change printing precision with torch.set_printoptions()\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "print(a.numpy()) # it is a view on the same storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1777,  0.7901,  1.0483],\n",
      "        [ 1.1322, -3.0079,  1.5753]], dtype=torch.float64)\n",
      "tensor([[ 1.1777,  0.7901,  1.0483],\n",
      "        [ 1.1322, -3.0079,  1.5753]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# torch.tensor() will *construct* a tensor, so it does a copy\n",
    "print(a)\n",
    "a_np[0, 0] = 77\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([44,  2,  3])\n"
     ]
    }
   ],
   "source": [
    "# from_numpy() won't make a copy\n",
    "# same with as_tensor()\n",
    "a_np = np.asarray([1, 2, 3])\n",
    "\n",
    "a = torch.from_numpy(a_np)\n",
    "print(a)\n",
    "a_np[0] = 44\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44)\n",
      "44 <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# how to get a python number from a tensor object?\n",
    "print(a[0])\n",
    "\n",
    "num = a[0].item()\n",
    "print(num, type(num))\n",
    "\n",
    "# Of course, we cannot get a python number from an N-dim tensor, if N>0\n",
    "# a.item() # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7],\n",
      "        [6]])\n",
      "tensor([[7, 1],\n",
      "        [4, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(0, 10, size=(2, 1))\n",
    "b = torch.randint(0, 10, size=(2, 2))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a + b =\n",
      "tensor([[14,  8],\n",
      "        [10, 10]])\n",
      "b @ a =\n",
      "tensor([[55],\n",
      "        [52]])\n",
      "a.T =\n",
      "tensor([[7, 6]])\n",
      "a.t() =\n",
      "tensor([[7, 6]])\n"
     ]
    }
   ],
   "source": [
    "print(\"a + b =\\n{}\".format(a + b))\n",
    "\n",
    "# about ampersand operator: https://www.python.org/dev/peps/pep-0465/\n",
    "print(\"b @ a =\\n{}\".format(b @ a))\n",
    "\n",
    "# dimensions inversion\n",
    "print(\"a.T =\\n{}\".format(a.T))\n",
    "\n",
    "# matrix transpose (https://pytorch.org/docs/stable/tensors.html#torch.Tensor.t)\n",
    "print(\"a.t() =\\n{}\".format(a.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4, 5, 6])\n",
      "torch.Size([6, 5, 4, 3, 2])\n",
      "torch.Size([4, 3, 2, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "c = torch.randint(0, 10, size=(2, 3, 4, 5, 6))\n",
    "print(c.size())\n",
    "print(c.T.size())\n",
    "print(c.transpose(0, 2).size())\n",
    "# print(c.t().size()) # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [0., 1.]])\n",
      "tensor([[1.4373e-33, 3.0623e-41, 1.4401e-33],\n",
      "        [3.0623e-41, 1.3563e-19, 1.2456e-11]])\n",
      "tensor([[1.4397e-33, 3.0623e-41, 1.4400e-33],\n",
      "        [3.0623e-41, 1.3563e-19, 1.2456e-11]])\n"
     ]
    }
   ],
   "source": [
    "# Different ways for creating a tensor - Factory Functions\n",
    "# https://pytorch.org/cppdocs/notes/tensor_creation.html#picking-a-factory-function\n",
    "\n",
    "print(torch.Tensor([[1, 0], [0, 1]]))\n",
    "print(torch.Tensor(2, 3))\n",
    "\n",
    "print(torch.empty(2, 3)) # it instatiate the storage without filling it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1],\n",
      "        [  2, 467]])\n",
      "torch.Size([2, 2])\n",
      "2\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0, 1], [2, 467]])\n",
    "\n",
    "print(a)\n",
    "print(a.size())\n",
    "print(a.dim()) # the order of the tensor\n",
    "print(a.numel())\n",
    "print(torch.numel(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0,   1,   2, 467]])\n",
      "2\n",
      "tensor([[[  0,   1],\n",
      "         [  2, 467]]])\n",
      "tensor([[  0,   1],\n",
      "        [  2, 467]])\n",
      "tensor([[33, 33],\n",
      "        [33, 33]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0, 1], [2, 467]])\n",
    "\n",
    "print(a.view(-1, 4))\n",
    "print(a.dim())\n",
    "print(a.unsqueeze(0))\n",
    "print(a.squeeze(0))\n",
    "print(a.fill_(33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([33, 33, 33, 33]) tensor([0, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([33, 33, 33, 33,  0,  1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.resize_(4)\n",
    "b = torch.tensor([0, 1])\n",
    "dim = 0\n",
    "\n",
    "print(a, b)\n",
    "torch.cat([a, b], dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.LongTensor\n",
      "tensor([33., 33., 33., 33.], dtype=torch.float64)\n",
      "tensor([33, 33, 33, 33])\n"
     ]
    }
   ],
   "source": [
    "# casting\n",
    "print(a.type())\n",
    "print(a.double())\n",
    "print(a)\n",
    "# .double()\n",
    "# .int()\n",
    "# .byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "# .cpu()\n",
    "# .cuda()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (999) : unknown error at /opt/conda/conda-bld/pytorch_1579022027550/work/aten/src/THC/THCGeneral.cpp:50",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f04293ee024f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pDL/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \"Cannot re-initialize CUDA in forked subprocess. \" + msg)\n\u001b[1;32m    196\u001b[0m         \u001b[0m_check_driver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0m_cudart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_cudart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0m_cudart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudaGetErrorName\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (999) : unknown error at /opt/conda/conda-bld/pytorch_1579022027550/work/aten/src/THC/THCGeneral.cpp:50"
     ]
    }
   ],
   "source": [
    "a = a.to('cuda')\n",
    "b = b.to('cuda')\n",
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling from a broader range of distr (in-place): use torch.empty()\n",
    "# https://pytorch.org/docs/stable/notes/serialization.html#recommend-saving-models\n",
    "torch.empty(2, 3).cauchy_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/torch.html#indexing-slicing-joining-mutating-ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving and loading a model\n",
    "# https://pytorch.org/docs/stable/torch.html#serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
